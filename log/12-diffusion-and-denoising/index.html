<!doctype html><html lang=en><head><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><meta content=ekunazanu name=author><meta content="Learning about statistics and diffusion models." name=description><meta content="Diffusion and Denoising" property=og:title><meta content=article property=og:type><meta content="Learning about statistics and diffusion models." property=og:description><meta content=https://ekunazanu.foo/log/12-diffusion-and-denoising/ property=og:url><meta content=https://ekunazanu.foo/thumbnails/log.12.distribution.avif.png property=og:image><meta content="Doodle of a normal distribution." property=og:image:alt><meta content=image/png property=og:image:type><meta content=1200 property=og:image:width><meta content=900 property=og:image:height><meta content=en_US property=og:locale><meta content=ekunazanu.foo property=og:site_name><title>Diffusion and Denoising ~ ekunazanu.foo</title><link href=https://ekunazanu.foo/log/12-diffusion-and-denoising/ rel=cannonical><link href=https://ekunazanu.foo/atom.xml rel=alternate type=application/atom+xml><link href=https://ekunazanu.foo/misc/main.css rel=stylesheet><link href=https://ekunazanu.foo/misc/favicon.png rel=icon><meta content=Zola name=generator><body><nav><ul><li><h2><a href=https://ekunazanu.foo>ekunazanu.foo</a></h2><li><a href=https://ekunazanu.foo/log>Log</a> ⟶<li><a href=https://ekunazanu.foo/lab>Lab</a></ul></nav><div class=print>https://ekunazanu.foo</div><main><article><h1>Diffusion and Denoising</h1><p>Did I learn about network protocols? No. Was I was bedridden this week? Yes. That is my justification. Nah, but I did learn a lot about diffusion models.<p>I think diffusion models are the most convincing arguments for the <a rel="noopener nofollow noreferrer" href=https://en.wikipedia.org/wiki/Manifold_hypothesis target=_blank>manifold hypothesis</a>, along with <a rel="noopener nofollow noreferrer" href=https://en.wikipedia.org/wiki/Variational_autoencoder target=_blank>VAEs</a>. But in a way, diffusion models are also autoencoders, just with non-parameterized encoding. But then, they can also be considered just <a rel="noopener nofollow noreferrer" href=https://sander.ai/2024/09/02/spectral-autoregression.html target=_blank>autoregression in the frequency domain</a>. Either way, diffusion models are powerful for how simple they are.<p>Okay, the theory behind diffusion models is ‘simple’ if you already know some statistics and probability theory. From a high level, diffusion models simply denoise data — by predicting the mean of the distribution to get structured data. The encoder part gradually adds random noise to the data and the decoder is trained to remove this noise.<p><img alt="a distribution transformed to a Gaussian distribution and then back to a similar distribution" decoding=async loading=lazy src=/media/log/diffusion-distribution.avif><p>Assume x is some structured data with some distribution. This is gradually corrupted by shifting its mean and adding noise: z = (1-β)x + β·ϵ, where ϵ is a random variable sampled from a standard normal distribution N(0, 1). In other words, z ~ N((1-β)x, β). This is done iteratively, adding small noise over multiple steps — well, the forward encoding process is actually done in a single step as the normal distribution is simply reparameterized. The decoding process however <em>does</em> use multiple iterations.<p>As said, the encoding will result in a new PDF given by q(z<sub>t</sub> | z<sub>t-1</sub>) = N((1-β)·z<sub>t</sub>, b), and when it is done in a single iteration till some final step T, then q(z<sub>T</sub> | x) = N(α·x, 1-α) where α is the products of 1−β<sub>t</sub>. That is, α = Π[1 − β<sub>t</sub>] — the new distribution parameter.<p>The decoder is slightly more complicated. Like other models, the goal is to minimize the negative-log-likelihood of the function. The decoder PDF must be the inverse of the encoder: q(z<sub>t-1</sub> | z<sub>t</sub>). And when performed iteratively until t = 0, we should get something similar to the original distribution x. A way to get q(z<sub>t-1</sub> | z<sub>t</sub>) from q(z<sub>t</sub> | z<sub>t-1</sub>) is via Bayes’ Theorem: q(z<sub>t-1</sub> | z<sub>t</sub>) = q(z<sub>t</sub> | z<sub>t-1</sub>) · q(z<sub>t-1</sub>) / q(z<sub>t</sub>). But this is marginal probability for all x. To be more accurate: q(z<sub>t</sub> | z<sub>t-1</sub>, x) · q(z<sub>t-1</sub>, x) / q(z<sub>t</sub> | x).<p>There’s some more clever rearranging that results in a easy-to-backpropagate lower bound from which the model is trained to maximize the probability of q(z<sub>t-1</sub> | z<sub>t</sub>). I am not completely confident of how the calculations works out, so I won’t spew non-sense here. I need to learn more about statistics.<p>But it is still magical that this is enough to create structured distributions from pure noise. Even complicated structured data like images. In fact, diffusion models are common in the generative image space — so common that it feels like they are half of the images on the internet now. I don’t mind generative art, but I also hope for a world where human art thrives, and art and IP rights are respected.<p><img alt="a doodle with ghibli colors of a portrait of a person in a forest surrounded by flowers" decoding=async loading=lazy src=/media/log/me-ghibli.avif><p>So, networking protocols and operating systems this week? Perhaps. I am also changing the upload schedule to monthly posts now, because (b)logging weekly is dragging down my productivity rather than improving it. Who would have thought.<p>Cya next month.</article></main><footer><a href=https://ekunazanu.foo/more#Terms_of_Use>© 2025</a> <a href=https://ekunazanu.foo/about>ekunazanu</a> · <a rel="noopener nofollow noreferrer" href=https://creativecommons.org/licenses/by/4.0/ target=_blank>CC BY 4.0</a> · <a rel="noopener nofollow noreferrer" href=https://github.com/ekunazanu/ekunazanu.foo target=_blank>Source</a></footer>